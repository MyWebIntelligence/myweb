# Bilan & plan ‚Äî Transfert LLM Validation (crawl + readable)

## 1. Contexte & objectifs
- Le legacy MyWebIntelligence d√©clenchait la **validation par LLM via OpenRouter** √† deux moments‚ÄØ:
  1. **Pendant le crawl** (`_legacy/core.py` lignes ~1860) pour filtrer les expressions non pertinentes (relevance = 0, tout en conservant la trace de traitement via `approved_at`).
  2. **Dans le pipeline readable** (`_legacy/readable_pipeline.py` lignes ~820) via l‚Äôoption `--llm`, recalculant `relevance`, `validllm`, `validmodel`.
- Le portage API a introduit `LLMValidationService` mais son int√©gration est incompl√®te, voire absente, dans les flux de production.
- Objectif‚ÄØ: dresser l‚Äô√©tat des lieux et planifier les actions pour retrouver la parit√© fonctionnelle (et profiter de l‚Äôinfrastructure moderne).

## 2. Comportement legacy √† reproduire
- **Crawl** :
  - `is_relevant_via_openrouter(land, expression)` appel√© apr√®s extraction, **avant** validation finale.
  - Si verdict `False`, alors `expression.relevance = 0` mais l‚Äôhorodatage `approved_at` reste la marque du passage du pipeline (il ne doit pas √™tre supprim√©).
  - Champs mis √† jour : `validllm` (`oui`/`non`), `validmodel`, `relevance` (√©ventuellement 0), et `approved_at` (date de traitement).
- **Pipeline Readable** :
  - Pipeline `run_readable_pipeline(..., llm_enabled)` recalcule pertinence via LLM si `readable` modifi√©.
  - Conservation de la pertinence locale mais remise √† 0 en cas de verdict n√©gatif, tout en laissant `approved_at` indiquer que le contenu a √©t√© r√©cup√©r√©.
  - `LandController.llm_validate` permet revalidation manuelle (batch).
- **Options CLI** : `--llm` pour `land readable`, commande `land llm validate`.

## 3. Impl√©mentation actuelle (API)
### 3.1 Crawl
- `CrawlRequest.enable_llm` existe (schemas, endpoints), stock√© dans `crawl_jobs.parameters`.
- **Mais** :
  - `tasks.crawl_land_task` ignore le param√®tre `enable_llm`.
  - `CrawlerEngine` (async) et `SyncCrawlerEngine` (sync, pour Celery) n'appellent **jamais** `LLMValidationService`.
  - `LLMValidationService` ne dispose que d‚Äôune interface `async`, ce qui le rend inutilisable directement par le `SyncCrawlerEngine`.
  - **Cons√©quence**‚ÄØ: `valid_llm`, `valid_model` et `relevance` ne sont jamais mis √† jour par le LLM pendant le crawl.

### 3.2 Pipeline Readable
- `ReadableService` (async) :
  - Appelle `LLMValidationService` si `enable_llm=True`.
  - `update_expression_validation` met √† jour `valid_llm`, `valid_model`, met `relevance=0` si non pertinent mais conserve `approved_at`. **Ceci est le comportement attendu.**
- `ReadableSimpleService` & `ReadableCeleryService` :
  - Commentaire explicite ‚Äúskip media/links/LLM validation‚Äù.
  - M√™me avec `enable_llm=True`, aucune validation n‚Äôest faite.
  - Recalcul pertinence simplifi√© (`update_expression_readable_simple`) qui n‚Äôinteragit pas avec LLM.
- T√¢che Celery `process_readable_task` utilise `ReadableSimpleService`, donc **aucune** validation LLM en production.
- Tests d‚Äôint√©gration `test_readable_endpoints` v√©rifient seulement la s√©rialisation du flag, pas l‚Äôeffet.

### 3.3 CLI / Services manquants
- Aucun √©quivalent API pour `land llm validate` (batch manuel).
- Pas de script de retraitement LLM (contrairement au legacy qui pouvait repasser sur les expressions).

## 4. √âcarts & impacts
| Zone | Legacy | API actuelle | Impact |
|---|---|---|---|
| Crawl (async/sync) | LLM gate actif | Flag ignor√©, pas de LLM | üî¥ **Critique**. Expressions non filtr√©es, `valid_llm` toujours `null`. |
| Readable (API directe) | LLM OK | ‚úÖ Parit√© (service async seulement) | Fonctionnel mais rarement utilis√© en pratique. |
| Readable (Celery) | LLM OK (legacy) | ‚ùå LLM ignor√© | üî¥ **Critique**. Le pipeline de production ne valide jamais via LLM. |
| Commande `land llm validate` | Oui | ‚ùå Absent | Aucun reprocessing manuel possible. |
| Tra√ßabilit√© | `validllm`, `validmodel` mis √† jour | Partiel, d√©pend du service | Incoh√©rences dans la base de donn√©es. |

## 5. Plan d‚Äôalignement
### Phase 1 ‚Äî Fondations (0.5 sprint)
1. **Wrapper Synchrone pour le Service LLM** :
   - Modifier `LLMValidationService` pour y ajouter une m√©thode `validate_expression_relevance_sync`.
   - Cette m√©thode sera un simple wrapper qui appellera la version `async` via `asyncio.run()`. Cela √©vite de dupliquer la logique.
   - Centraliser la gestion des timeouts, retries et du "circuit breaker" (d√©sactivation temporaire si l'API OpenRouter √©choue) dans ce service.

### Phase 2 ‚Äî Int√©gration crawl (1 sprint)
1. **Propagation du flag `enable_llm`** :
   - `crawling_service.start_crawl_for_land` ‚Üí stocker flag.
   - `tasks.crawling_task.crawl_land_task` ‚Üí extraire le flag des param√®tres et le passer au moteur.
2. **Modification des deux crawlers (Double Crawler)** :
   - Dans `crawler_engine.py` (async) : apr√®s le calcul de pertinence, si `enable_llm` est vrai, appeler `LLMValidationService.validate_expression_relevance`.
   - Dans `crawler_engine_sync.py` (sync) : faire de m√™me en appelant la nouvelle m√©thode `LLMValidationService.validate_expression_relevance_sync`.
   - **Crucial** : Mettre √† jour `valid_llm`, `valid_model`, et `relevance` (√† 0 si non pertinent) tout en s'assurant que `approved_at` est bien horodat√© pour marquer l'expression comme trait√©e.
3. **Tests de parit√©** :
   - Mettre √† jour les scripts `test-crawl-async.sh` et `test-crawl-simple.sh` pour inclure un cas avec `enable_llm=true`.
   - Utiliser des mocks (ex: `respx`) pour simuler les r√©ponses d'OpenRouter et √©viter des appels r√©els co√ªteux.

### Phase 3 ‚Äî Harmonisation readable (0.5 sprint)
1. **Refactoriser les services `readable`** :
   - Modifier `ReadableSimpleService` et `ReadableCeleryService` pour qu'ils appellent `LLMValidationService` (via son wrapper sync) si `enable_llm=True`.
   - Supprimer les commentaires "skip LLM validation" et impl√©menter la logique manquante.
2. **Mise √† jour de la t√¢che Celery** :
   - S'assurer que la t√¢che `process_readable_task` propage bien le param√®tre `enable_llm` au service qu'elle utilise.

### Phase 4 ‚Äî Outils & reprocessing (0.5 sprint)
1. **Endpoint de revalidation** : Cr√©er une route `POST /api/v2/lands/{id}/llm-validate` qui lance une t√¢che Celery `llm_validate_task`.
2. **Script de reprocessing** : Cr√©er un script `scripts/reprocess_llm_validation.py` pour rejouer la validation sur des expressions existantes (par land, par date, etc.).
3. **Documentation** : Cr√©er un guide `docs/LLM_VALIDATION_GUIDE.md` expliquant la configuration, l'utilisation, les co√ªts et le monitoring.

### Phase 5 ‚Äî Observabilit√© & QA (0.5 sprint)
-1. **Logs Structur√©s** : Ajouter des logs clairs indiquant la source de l'appel LLM (`crawl`, `readable`, `manual`), le verdict, le mod√®le utilis√© et la latence.
-2. **M√©triques Prometheus** : Instrumenter les appels avec des compteurs : `llm_validation_requests_total{source="crawl|readable"}`, `llm_validation_failures_total`, et un histogramme `llm_validation_duration_seconds`.
-3. **Tests de non-r√©gression** :
   - Crawl avec enable_llm true/false.
   - Pipeline readable (via Celery) avec `enable_llm: true`.
   - Ex√©cution du script de reprocessing en `dry-run`.

## 6. Backlog prioris√©
| ID | Cat√©gorie | Description | Livrable |
|---|---|---|---|
| LLM-01 | Core | Ajouter un wrapper `_sync` √† `LLMValidationService` pour le rendre compatible avec Celery. | M√©thode `validate_..._sync` + tests unitaires. |
| LLM-02 | Crawl | Int√©grer l'appel au service LLM dans `crawler_engine.py` (async). | Code + tests d'int√©gration (mock). |
| LLM-03 | Crawl | **[Double Crawler]** Int√©grer l'appel dans `crawler_engine_sync.py` (sync). | Code + tests d'int√©gration (mock). |
| LLM-04 | Readable | Aligner `ReadableSimpleService` et `ReadableCeleryService` pour qu'ils utilisent le service LLM. | Refactoring des services + tests. |
| LLM-05 | API | Cr√©er l'endpoint `POST /lands/{id}/llm-validate` et la t√¢che Celery associ√©e. | Route API, t√¢che Celery, sch√©ma Pydantic. |
| LLM-06 | Outils | Cr√©er le script de reprocessing `scripts/reprocess_llm_validation.py`. | Script Python avec CLI (Typer/argparse). |
| LLM-07 | Observabilit√© | Ajouter les logs structur√©s et les m√©triques Prometheus. | Code d'instrumentation + exemples de logs/m√©triques. |
| LLM-08 | Tests | Cr√©er un script de test de non-r√©gression `test-llm-pipeline.sh`. | Script shell validant le workflow complet. |
| LLM-09 | Docs | R√©diger le guide `docs/LLM_VALIDATION_GUIDE.md`. | Fichier Markdown. |

## 7. Crit√®res d‚Äôacceptation
- `enable_llm` influe r√©ellement sur crawl (sync + async) et readable (toutes variantes).
- `valid_llm`, `valid_model`, `relevance` et `approved_at` mis √† jour conform√©ment au legacy (pas de remise √† null d‚Äô`approved_at` lors d‚Äôun verdict n√©gatif, seulement `relevance=0`).
- Commande/API de revalidation disponible.
- Tests automatis√©s (avec mocks) couvrant les cas de succ√®s, √©chec et timeout de l'API OpenRouter.
- Documentation + monitoring op√©rationnels.

## 8. Risques & mitigations
- **Co√ªt OpenRouter** : Impl√©menter un "circuit breaker" qui d√©sactive temporairement les appels LLM si le taux d'erreur d√©passe un seuil (ex: 5 √©checs cons√©cutifs). Logger un `WARNING` clair.
- **Temps de r√©ponse** : Utiliser des timeouts stricts (`httpx.Timeout`) et ex√©cuter la validation LLM en fin de traitement pour ne pas bloquer les autres extractions.
- **Double crawler** : Appliquer rigoureusement la checklist de `.claude/AGENTS.md` et ex√©cuter les scripts de test `test-crawl-async.sh` et `test-crawl-simple.sh` apr√®s modification.
- **Propagation des erreurs** : En cas d‚Äô√©chec de l'API LLM, logger l'erreur, d√©finir `valid_llm='error'`, et **ne jamais** bloquer le reste du pipeline de crawl/readable.

## 9. Prochaines √©tapes imm√©diates
1. **Valider le plan** avec l'√©quipe pour confirmer les priorit√©s.
2. **Commencer par LLM-01** (Wrapper sync), car il d√©bloque l'int√©gration dans le crawler sync et les services readable de production.
3. **Pr√©parer l'environnement de test** avec des mocks pour l'API OpenRouter (`respx` est un bon candidat) afin de permettre des tests CI/CD rapides et sans co√ªt.
