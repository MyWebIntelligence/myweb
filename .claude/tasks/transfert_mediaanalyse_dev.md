# Plan de suivi ‚Äî Pipeline MediaAnalyse (legacy ‚Üí API)

## 1. Contexte & objectifs
- Le legacy fournit la commande `land medianalyse` qui traite toutes les entr√©es `media` d‚Äôun land via `core.medianalyse_land` (MediaAnalyzer, filtres dimension/poids, mise √† jour DB).
- L‚ÄôAPI moderne expose un endpoint `POST /lands/{id}/medianalyse` (v1/v2) qui d√©clenche la t√¢che Celery `analyze_land_media_task`.
- Le transfert est bien avanc√© : logique Celery, filtrage SQL, extraction via `MediaProcessor` sont d√©j√† en place. **Objectif final** : assurer la parit√© totale, am√©liorer la robustesse et consolider le pipeline (observabilit√©, export, docs).

## 2. H√©ritage legacy assur√©
- **S√©l√©ction m√©dias** : jointure `Media`‚Üí`Expression`, filtres `depth`, `relevance`, `limit` (legacy). L‚ÄôAPI reprend depth/minrel.
- **Analyse** : MediaAnalyzer (legacy) vs `MediaProcessor` (API) ‚Üí extraction dimensions, format, EXIF, couleurs, perceptual hash.
- **Mise √† jour DB** : champs media (width, height, dominant_colors, hash, is_processed, analyzed_at, etc.).
- **Workflow** : CLI -> boucle sync, API -> Celery async (batch + group tasks).
- **Journalisation** : logs `MEDIA ANALYSIS STARTED/COMPLETED`, stats (analysed/failed).
- **T√¢che Celery** : `analyze_land_media_task` d√©j√† impl√©ment√©e.

## 3. √âtat API actuel (2025-10)
- Endpoint v1/v2 : `land medianalyse` ‚Üí create job (`media_analysis`), lance `analyze_land_media_task`.
- Service interne : `media_analysis_task.py` g√®re:
  - S√©lection expressions (SQL brut).
  - S√©lection m√©dias non trait√©s (`type='IMAGE'`, `is_processed` false/null).
  - Traitement direct < batch_size, sinon sous-t√¢ches Celery group√©es.
  - Mise √† jour job + logs + result data.
- `MediaProcessor` (`app/core/media_processor.py`) g√®re t√©l√©chargement via httpx, validations, extraction PIL/sklearn.
- Observabilit√© partielle : logs, r√©sultat job. Pas de m√©triques Prometheus ni WebSocket de progression (√† v√©rifier).
- Exports : `ExportService` prend en compte `media` (√† confirmer pour champs analytiques).
- Documentation : README/API mentionne le pipeline, mais pas de guide d√©di√©.

## 4. Parit√© vs legacy
| Aspect | Legacy | API | Statut |
|--------|--------|-----|--------|
| Commande d√©clenchement | CLI sync | Endpoint + Celery | ‚úÖ (am√©lior√©) |
| Filtres | depth, minrel | depth, minrel | ‚úÖ |
| Type m√©dia | Tous (legacy) | Filtre `type='IMAGE'` | üü° (√† confirmer) |
| Re-analyses | Toujours (legacy) | `is_processed` False | ‚úÖ (respect DB flag) |
| Analyse | MediaAnalyzer (aiohttp) | MediaProcessor (httpx) | üü° (assurer feature parity) |
| Stats retour | processed_count | result dict (analyzed, failed) | ‚úÖ |
| Logs | stdout | logging + job result | ‚úÖ |
| CLI feedback | Console | API JSON / Celery job | ‚úÖ |
| Tests | manuels | partiels (√† compl√©ter) | üü° |

## 5. Travaux restants
1. **Parit√© extraction** :
   - **Critique** : V√©rifier que MediaProcessor couvre toutes les features legacy (EXIF, dominant colors, perceptual hash : pHash, dHash, cHash).
   - Confirmer que les filtres min_width/min_height/max_file_size sont appliqu√©s (config).
   - Ajouter support pour autres types (`VIDEO`, `AUDIO`) si legacy le faisait (legacy mentionne images surtout).
2. **Observabilit√© / UX** :
   - **Critique** : Ajouter WebSocket progress (via `websocket_manager`) pour le suivi en temps r√©el.
   - Exposer m√©triques Prometheus (`media_analysis_processed_total`, `media_analysis_failures_total`).
   - Inclure success_rate dans job.result.
3. **Exports & consumers** :
   - Confirmer que `ExportService` fait remonter les champs (dimensions, couleurs).
   - Doc pour data analysts (colonne `media` dans CSV/GEXF).
4. **Tests** :
   - Tests unitaires MediaProcessor avec fixtures (images valides, corrompues, trop lourdes).
   - Tests d‚Äôint√©gration : pipeline complet, assertions sur base (`is_processed`, `analyzed_at`).
   - Tests Celery group (multi batch).
5. **Documentation** :
   - Ajouter `.claude/docs/MEDIA_ANALYSIS_GUIDE.md` (d√©j√† existant ? √† v√©rifier).
   - Mettre √† jour `.claude/INDEX_DOCUMENTATION.md`, README (workflow, params depth/minrel/batch).
6. **Robustesse & Configuration** :
   - **Nouveau** : Centraliser la configuration (`MEDIA_ANALYSIS_TIMEOUT`, `MEDIA_ANALYSIS_MAX_FILE_SIZE`, etc.) dans `app/config.py`.
   - **Nouveau** : Impl√©menter une logique de retries avec backoff exponentiel dans `MediaProcessor` pour les erreurs r√©seau (429, 503).
7. **Outils D√©veloppeur** :
   - **Nouveau** : Cr√©er un script de reprocessing `scripts/reprocess_media.py` avec options `--land-id`, `--force`, `--dry-run`.

## 6. Backlog r√©siduel
| ID | Cat√©gorie | Description | Livrable | Owner |
|----|-----------|-------------|----------|-------|
| MA-01 | V√©rif | Audit parit√© MediaProcessor vs MediaAnalyzer legacy | Rapport | Tech Lead |
| MA-02 | Core | Impl√©menter les filtres de configuration (taille, dimensions) et la logique de retries. | `MediaProcessor` mis √† jour | Dev A |
| MA-03 | Core | Ajouter le support multi-type (VIDEO, AUDIO) si pertinent. | Impl√©mentation | Dev A |
| MA-04 | Observabilit√© | Int√©grer WebSocket progress et m√©triques Prometheus. | Code + Dashboard | DevOps |
| MA-05 | Exports | Confirmer l'export des champs m√©dia (dimensions, couleurs, hash) dans les CSV/GEXF. | Tests + code | Dev B |
| MA-06 | Tests | Cr√©er une suite de tests unitaires et d'int√©gration compl√®te pour `MediaProcessor` et la t√¢che Celery. | Fichiers de test | QA |
| MA-07 | Outils | Cr√©er le script de reprocessing `scripts/reprocess_media.py`. | Script Python | Dev B |
| MA-08 | Docs | R√©diger le guide `MEDIA_ANALYSIS_GUIDE.md` et mettre √† jour la documentation existante. | Documentation | Tech Writer |

## 7. Crit√®res d‚Äôacceptation finaux
- `POST /lands/{id}/medianalyse` ‚Üí job Celery, logs, result complet (analyzed, failed, success_rate).
- MediaProcessor supporte dimensions, format, EXIF, couleurs, perceptual hash comme legacy.
- **Les filtres de configuration (taille, dimensions) sont fonctionnels.**
- Exports contiennent champs analytiques.
- Tests (unitaires + int√©gration) valid√©s.
- Docs + monitoring √† jour.

## 8. Risques & mitigations
- **Volume m√©dia important** : batch + group tasks d√©j√† en place; surveiller limites concurrency httpx.
- **Type non support√©** : fallback/skip logg√©s; config pour activer/d√©sactiver.
- **Resources CPU** : analyser usage PIL/sklearn (option de downscale).
- **Double crawler** : Non concern√© directement pour l'analyse, mais **critique pour la cr√©ation des entr√©es `Media`**. S'assurer que `crawler_engine.py` et `crawler_engine_sync.py` cr√©ent les enregistrements `Media` de mani√®re identique.

## 9. Prochaines √©tapes
1. Conduire l‚Äôaudit parit√© (MA-01) et lister gaps.
2. Prioriser MA-02, MA-04, MA-06 (robustesse, observabilit√©, tests).
3. Documenter le pipeline final (MA-08) avant la release.
