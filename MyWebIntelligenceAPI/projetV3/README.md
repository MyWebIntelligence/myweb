# MyWebIntelligence V3 - Architecture Async/Parall√®le

**Statut:** üöß EN D√âVELOPPEMENT
**Date de cr√©ation:** 19 octobre 2025
**Raison:** Simplification de la V2 en version synchrone stable

---

## üéØ Objectif

La **V3** repr√©sente l'√©volution avanc√©e de MyWebIntelligence avec des capacit√©s async/parall√®les pour am√©liorer les performances et la scalabilit√©. Cette version est en d√©veloppement et n√©cessite r√©solution de bugs critiques avant production.

### Fonctionnalit√©s V3

- ‚úÖ **Crawling HTTP parall√®le** : `asyncio.gather()` pour crawler plusieurs URLs simultan√©ment
- ‚úÖ **Pipeline readable asynchrone** : Extraction de contenu en parall√®le avec fallbacks (Trafilatura ‚Üí Archive.org)
- ‚úÖ **Analyse m√©dia parall√®le** : Traitement d'images concurrent avec PIL/sklearn
- ‚úÖ **Syst√®me d'embeddings** : G√©n√©ration de vecteurs pour recherche s√©mantique (OpenAI, Mistral)
- ‚úÖ **WebSocket temps r√©el** : Monitoring de progression des jobs via WebSocket
- ‚ö†Ô∏è **Bugs connus** : Erreurs `greenlet_spawn` dans extraction de liens, conflicts SQLAlchemy session

---

## üîÑ Pourquoi V3 est s√©par√©e de V2?

La V2 reste **simple, stable et synchrone** pour garantir :
- Maintenance facile
- Debuggage rapide
- Pas de complexit√© async inutile pour la majorit√© des cas d'usage

La V3 ajoute **complexit√© et performance** pour :
- Crawls massifs (>1000 URLs)
- Analyse m√©dia intensive
- Recherche s√©mantique avanc√©e
- Applications n√©cessitant temps r√©el

**D√©cision:** Garder V2 simple (prod stable) et d√©velopper V3 en parall√®le (exp√©rimental).

---

## üì¶ Code d√©plac√© de V2 vers V3

### Date de migration: 19 octobre 2025

### Core modules (async)
- `app/core/crawler_engine.py` ‚Üí `projetV3/app/core/crawler_engine_async.py` (867 lignes)
  - AsyncCrawlerEngine avec parall√©lisation HTTP
  - M√©thode `crawl_expressions_parallel()` avec `asyncio.gather()`
  - Support `max_concurrent` pour contr√¥le concurrence

- `app/core/media_processor.py` ‚Üí `projetV3/app/core/media_processor_async.py` (286 lignes)
  - Analyse d'images asynchrone avec httpx
  - Extraction couleurs dominantes (sklearn)
  - Traitement EXIF et hashing

- `app/core/readable_*.py` ‚Üí `projetV3/app/core/` (177 + 123 = 300 lignes)
  - Pipeline readable asynchrone
  - Fallbacks Trafilatura ‚Üí Archive.org
  - Gestion markdown enrichi

- `app/core/websocket.py` ‚Üí `projetV3/app/core/websocket.py` (36 lignes)
  - WebSocketManager pour progression temps r√©el
  - Broadcast aux clients connect√©s

- `app/core/embedding_providers/` ‚Üí `projetV3/app/core/embedding_providers/` (tout le dossier)
  - Providers OpenAI, Mistral
  - G√©n√©ration embeddings pour paragraphes
  - Calcul similarit√© cosinus

### Services async
- `app/services/readable_*.py` ‚Üí `projetV3/app/services/` (3 fichiers)
- `app/services/embedding_service.py` ‚Üí `projetV3/app/services/`

### Tasks Celery async complexes
- `app/tasks/readable_*.py` ‚Üí `projetV3/app/tasks/` (3 fichiers)
- `app/tasks/embedding_tasks.py` ‚Üí `projetV3/app/tasks/`
- `app/tasks/text_processing_tasks.py` ‚Üí `projetV3/app/tasks/`
- `app/tasks/media_analysis_task.py` ‚Üí `projetV3/app/tasks/`

### Documentation technique
- `.claude/tasks/async_parallele.md` ‚Üí `projetV3/docs/`
- `.claude/tasks/README_TEST_ASYNC.md` ‚Üí `projetV3/docs/`
- `.claude/tasks/QUICKSTART_TEST_ASYNC.md` ‚Üí `projetV3/docs/`
- `.claude/tasks/align_sync_async.md` ‚Üí `projetV3/docs/`

### Tests async
- `tests/test-crawl-async.sh` ‚Üí `projetV3/tests/` (si existe)

---

## üêõ Bugs connus √† r√©soudre avant production

### 1. ‚ùå Erreur `greenlet_spawn` dans extraction de liens

**Sympt√¥me:**
```
Error processing markdown link: greenlet_spawn has not been called;
can't call await_only() here. Was IO attempted in an unexpected place?
```

**Localisation:** `crawler_engine_async.py` lignes 546-624 (`_create_links_from_markdown`, `_extract_and_save_links`)

**Impact:**
- ‚úÖ Crawl principal fonctionne
- ‚úÖ M√©tadonn√©es extraites
- ‚ùå Liens entre expressions non cr√©√©s
- ‚ùå Graphe de navigation incomplet

**Solution requise:** Refactoriser l'extraction de liens pour √©viter appels synchrones dans contexte async

---

### 2. ‚ùå Conflicts SQLAlchemy session en mode parall√®le

**Sympt√¥me:**
```
sqlalchemy.exc.InterfaceError: another operation is in progress
```

**Impact:** Commits parall√®les causent des conflicts de session

**Solution actuelle (partielle):**
- Phase 1: HTTP parall√®le (`asyncio.gather`)
- Phase 2: DB s√©quentielle (1 commit par expression)

**Solution optimale requise:** Pool de sessions ou queue de commits

---

### 3. ‚ö†Ô∏è Performance d√©grad√©e sans tuning

**Probl√®me:** `max_concurrent=10` par d√©faut peut √™tre trop/pas assez selon infrastructure

**Solution requise:**
- Profiling pour d√©terminer optimal
- Configuration dynamique selon charge
- Rate limiting par domaine

---

## üìä Comparaison V2 (Sync) vs V3 (Async/Parall√®le)

| Aspect | V2 Sync | V3 Async |
|--------|---------|----------|
| **Dur√©e (5 URLs)** | ~30s | ~10s (3x plus rapide) |
| **Concurrence HTTP** | 1 requ√™te/fois | 10 requ√™tes simultan√©es |
| **Complexit√© code** | Simple | Mod√©r√©e-√âlev√©e |
| **Debugging** | Facile | Difficile (race conditions) |
| **Maintenance** | Faible | Moyenne-√âlev√©e |
| **Stabilit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê (bugs connus) |
| **Usage recommand√©** | Production stable | D√©veloppement/Tests |

---

## üöÄ Roadmap V3

### Phase 1: Correction bugs critiques (2-3 jours)
- [ ] R√©soudre `greenlet_spawn` dans extraction liens
- [ ] Impl√©menter pool de sessions SQLAlchemy
- [ ] Tests unitaires complets pour chaque composant async

### Phase 2: Performance tuning (1-2 jours)
- [ ] Profiling performance (HTTP vs DB vs Processing)
- [ ] Configuration dynamique `max_concurrent`
- [ ] Rate limiting par domaine
- [ ] Retry logic pour √©checs HTTP

### Phase 3: Pipeline readable production-ready (2-3 jours)
- [ ] Stabiliser fallbacks Trafilatura ‚Üí Archive.org
- [ ] Gestion erreurs robuste
- [ ] Tests de charge (100+ URLs)
- [ ] Monitoring m√©triques (Prometheus)

### Phase 4: Syst√®me embeddings complet (3-4 jours)
- [ ] Support providers additionnels (Cohere, Voyage)
- [ ] G√©n√©ration paragraphes optimis√©e
- [ ] Index vectoriel (FAISS/Pinecone)
- [ ] API recherche s√©mantique

### Phase 5: WebSocket production (1 jour)
- [ ] Authentification WebSocket
- [ ] Reconnexion automatique
- [ ] Monitoring connexions actives

### Phase 6: Tests et d√©ploiement (2-3 jours)
- [ ] Tests d'int√©gration complets
- [ ] Tests de performance (benchmark V2 vs V3)
- [ ] Documentation API compl√®te
- [ ] Guide migration V2 ‚Üí V3

**Estimation totale:** 12-18 jours de d√©veloppement

---

## üß™ Tests

### Tests unitaires
```bash
# Crawler async
pytest projetV3/tests/unit/test_crawler_async.py -v

# Media processor async
pytest projetV3/tests/unit/test_media_processor_async.py -v

# Embeddings
pytest projetV3/tests/unit/test_embeddings.py -v
```

### Tests d'int√©gration
```bash
# Crawl async complet
./projetV3/tests/test-crawl-async.sh

# Readable pipeline
./projetV3/tests/test-readable-async.sh
```

### Benchmarks
```bash
# Comparaison V2 vs V3
python projetV3/tests/benchmark_v2_vs_v3.py --urls 100
```

---

## üìö Documentation technique

- [async_parallele.md](docs/async_parallele.md) - Plan de d√©veloppement crawling parall√®le
- [README_TEST_ASYNC.md](docs/README_TEST_ASYNC.md) - Proc√©dure de test async
- [QUICKSTART_TEST_ASYNC.md](docs/QUICKSTART_TEST_ASYNC.md) - Guide rapide tests
- [align_sync_async.md](docs/align_sync_async.md) - Alignement sync/async (CRITIQUE)

---

## üí° Notes de d√©veloppement

### Bonnes pratiques async
1. **Toujours** utiliser `asyncio.create_task()` pour parall√©lisme
2. **Jamais** m√©langer appels sync et async sans `run_in_executor()`
3. **Toujours** g√©rer timeouts avec `asyncio.wait_for()`
4. **Toujours** cleanup resources avec `try/finally` ou context managers

### Gestion SQLAlchemy async
```python
# ‚úÖ BON - Session isol√©e par requ√™te
async with AsyncSessionLocal() as session:
    result = await session.execute(query)
    await session.commit()

# ‚ùå MAUVAIS - R√©utilisation session entre tasks parall√®les
session = AsyncSessionLocal()
tasks = [process_url(session, url) for url in urls]
await asyncio.gather(*tasks)  # ‚ùå Conflict!
```

### Semaphore pour contr√¥le concurrence
```python
semaphore = asyncio.Semaphore(max_concurrent)

async def fetch_with_limit(url):
    async with semaphore:
        return await http_client.get(url)

results = await asyncio.gather(*[fetch_with_limit(url) for url in urls])
```

---

## üîó Ressources

- [AsyncIO Best Practices](https://docs.python.org/3/library/asyncio.html)
- [SQLAlchemy Async ORM](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)
- [FastAPI Async](https://fastapi.tiangolo.com/async/)

---

## üìû Contact

Pour questions/contributions sur V3 :
- Issues GitHub: [tag:v3-async]
- Documentation: `.claude/docs/`
- Tests: `projetV3/tests/`

**Maintenu par:** √âquipe MyWebIntelligence
**Derni√®re mise √† jour:** 19 octobre 2025
