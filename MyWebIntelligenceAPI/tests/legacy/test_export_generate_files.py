"""
Test de g√©n√©ration r√©elle de fichiers d'export
Cr√©e tous les formats d'export avec des donn√©es de test et affiche les chemins
"""

import pytest
import asyncio
import os
import tempfile
from datetime import datetime
from zipfile import ZipFile
from lxml import etree

from app.db.base import AsyncSessionLocal
from app.services.export_service import ExportService
from app.services.export_service_sync import SyncExportService
from app.crud.crud_land import land as land_crud
from app.crud.crud_user import user as user_crud
from app.crud.crud_expression import expression as expression_crud
from app.crud.crud_domain import domain as domain_crud
from app.schemas.land import LandCreate
from app.schemas.user import UserCreate
from app.schemas.expression import ExpressionCreate
from app.schemas.domain import DomainCreate


@pytest.mark.asyncio
class TestExportFileGeneration:
    """Test de g√©n√©ration r√©elle de fichiers d'export"""
    
    async def setup_method(self):
        """Setup avec donn√©es de test r√©alistes"""
        self.db = AsyncSessionLocal()
        self.generated_files = []
        
        # Create test user
        user_data = UserCreate(
            email=f"export_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}@example.com",
            password="testpassword123",
            full_name="Export File Test User"
        )
        self.test_user = await user_crud.create(self.db, obj_in=user_data)
        
        # Create test land
        land_data = LandCreate(
            name="Actualit√©s Tech Export",
            description="Land de test pour g√©n√©ration de fichiers d'export avec donn√©es r√©alistes",
            lang=["fr"],
            user_id=self.test_user.id
        )
        self.test_land = await land_crud.create(self.db, obj_in=land_data)
        
        # Create test domains
        self.test_domains = []
        domain_data_list = [
            {
                "name": "techcrunch.com",
                "title": "TechCrunch",
                "description": "Site d'actualit√©s technologiques",
                "keywords": "tech,startup,innovation"
            },
            {
                "name": "lemonde.fr", 
                "title": "Le Monde",
                "description": "Journal fran√ßais d'information",
                "keywords": "actualit√©s,france,monde"
            },
            {
                "name": "github.com",
                "title": "GitHub",
                "description": "Plateforme de d√©veloppement collaboratif",
                "keywords": "code,git,d√©veloppement"
            }
        ]
        
        for domain_data in domain_data_list:
            domain = await domain_crud.create(self.db, obj_in=DomainCreate(**domain_data))
            self.test_domains.append(domain)
        
        # Create realistic test expressions
        self.test_expressions = []
        expression_data_list = [
            {
                "url": "https://techcrunch.com/2025/07/04/ai-breakthrough-new-language-model",
                "title": "AI Breakthrough: Revolutionary New Language Model Achieves Human-Level Understanding",
                "description": "Researchers announce a major breakthrough in artificial intelligence with a new language model that demonstrates unprecedented understanding capabilities.",
                "keywords": "AI,artificial intelligence,language model,breakthrough,technology",
                "readable": "Une √©quipe de chercheurs vient d'annoncer une perc√©e majeure dans le domaine de l'intelligence artificielle. Leur nouveau mod√®le de langage d√©montre des capacit√©s de compr√©hension sans pr√©c√©dent, approchant le niveau de compr√©hension humaine. Cette avanc√©e pourrait r√©volutionner de nombreux secteurs, de l'√©ducation √† la m√©decine en passant par la recherche scientifique. Les implications de cette technologie sont vastes et promettent de transformer notre fa√ßon d'interagir avec les machines.",
                "relevance": 9,
                "depth": 1,
                "http_status": 200,
                "land_id": self.test_land.id,
                "domain_id": self.test_domains[0].id
            },
            {
                "url": "https://lemonde.fr/technologies/2025/07/04/france-investit-ia-recherche",
                "title": "La France investit massivement dans la recherche en intelligence artificielle",
                "description": "Le gouvernement fran√ßais annonce un plan d'investissement de 2 milliards d'euros pour d√©velopper la recherche en IA sur le territoire national.",
                "keywords": "France,investissement,IA,recherche,gouvernement,technologie",
                "readable": "Le gouvernement fran√ßais a d√©voil√© aujourd'hui un ambitieux plan d'investissement de 2 milliards d'euros destin√© √† positionner la France comme un leader mondial de la recherche en intelligence artificielle. Ce plan pr√©voit la cr√©ation de nouveaux centres de recherche, le financement de startups innovantes, et le d√©veloppement de partenariats avec les universit√©s europ√©ennes. L'objectif est de cr√©er un √©cosyst√®me fran√ßais comp√©titif face aux g√©ants am√©ricains et chinois de la tech.",
                "relevance": 8,
                "depth": 1,
                "http_status": 200,
                "land_id": self.test_land.id,
                "domain_id": self.test_domains[1].id
            },
            {
                "url": "https://github.com/blog/2025-07-04-copilot-updates",
                "title": "GitHub Copilot: Major Updates Enhance Developer Productivity",
                "description": "GitHub announces significant improvements to Copilot, including better code suggestions and multi-language support.",
                "keywords": "GitHub,Copilot,AI,programming,development,productivity",
                "readable": "GitHub vient d'annoncer des am√©liorations majeures de son assistant de programmation Copilot. Ces mises √† jour incluent des suggestions de code plus pr√©cises, un support √©tendu pour de nouveaux langages de programmation, et une int√©gration am√©lior√©e avec les environnements de d√©veloppement populaires. Les d√©veloppeurs peuvent maintenant b√©n√©ficier d'une assistance IA plus sophistiqu√©e pour acc√©l√©rer leur productivit√© et r√©duire les erreurs de code.",
                "relevance": 7,
                "depth": 2,
                "http_status": 200,
                "land_id": self.test_land.id,
                "domain_id": self.test_domains[2].id
            },
            {
                "url": "https://techcrunch.com/2025/07/04/quantum-computing-commercial-breakthrough",
                "title": "Quantum Computing Reaches Commercial Viability Milestone",
                "description": "First commercially viable quantum computer announced by leading tech company, marking a new era in computing.",
                "keywords": "quantum computing,commercial,breakthrough,technology,computing",
                "readable": "Une entreprise technologique leader vient d'annoncer le premier ordinateur quantique commercialement viable, marquant une nouvelle √®re dans l'informatique. Cette machine r√©volutionnaire promet de r√©soudre des probl√®mes complexes en quelques secondes, l√† o√π les ordinateurs traditionnels prendraient des ann√©es. Les applications potentielles incluent la cryptographie, la d√©couverte de m√©dicaments, et l'optimisation logistique. Cette avanc√©e pourrait transformer radicalement de nombreux secteurs industriels.",
                "relevance": 8,
                "depth": 1,
                "http_status": 200,
                "land_id": self.test_land.id,
                "domain_id": self.test_domains[0].id
            },
            {
                "url": "https://lemonde.fr/sciences/2025/07/04/recherche-medicale-ia-diagnostic",
                "title": "L'IA r√©volutionne le diagnostic m√©dical en France",
                "description": "Des chercheurs fran√ßais d√©veloppent une IA capable de diagnostiquer des maladies rares avec une pr√©cision sup√©rieure aux m√©decins.",
                "keywords": "IA,m√©decine,diagnostic,recherche,France,sant√©",
                "readable": "Une √©quipe de chercheurs fran√ßais a d√©velopp√© un syst√®me d'intelligence artificielle r√©volutionnaire capable de diagnostiquer des maladies rares avec une pr√©cision remarquable, souvent sup√©rieure √† celle des m√©decins sp√©cialis√©s. Cette technologie analyse des images m√©dicales, des sympt√¥mes et des donn√©es g√©n√©tiques pour identifier des pathologies complexes. Les premiers tests cliniques montrent des r√©sultats prometteurs qui pourraient transformer la m√©decine de pr√©cision et am√©liorer significativement les soins aux patients.",
                "relevance": 6,
                "depth": 2,
                "http_status": 200,
                "land_id": self.test_land.id,
                "domain_id": self.test_domains[1].id
            }
        ]
        
        for expr_data in expression_data_list:
            expression = await expression_crud.create(self.db, obj_in=ExpressionCreate(**expr_data))
            self.test_expressions.append(expression)
    
    async def teardown_method(self):
        """Cleanup apr√®s tests"""
        # Note: We keep the generated files for user inspection
        print(f"\nüìÅ Files generated and available at:")
        for file_path in self.generated_files:
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                print(f"  ‚Ä¢ {file_path} ({file_size} bytes)")
        
        # Clean up test data
        for expression in self.test_expressions:
            await expression_crud.remove(self.db, id=expression.id)
        
        for domain in self.test_domains:
            await domain_crud.remove(self.db, id=domain.id)
        
        await land_crud.remove(self.db, id=self.test_land.id)
        await user_crud.remove(self.db, id=self.test_user.id)
        
        await self.db.close()
    
    async def test_generate_all_export_formats(self):
        """Test principal: g√©n√®re tous les formats d'export"""
        export_service = ExportService(self.db)
        
        # Cr√©er un r√©pertoire de sortie avec timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"/tmp/mywebintelligence_exports_{timestamp}"
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"\nüéØ G√©n√©ration de fichiers d'export dans: {output_dir}")
        print(f"üìä Land: '{self.test_land.name}' (ID: {self.test_land.id})")
        print(f"üìÑ {len(self.test_expressions)} expressions de test")
        print(f"üåê {len(self.test_domains)} domaines de test")
        
        # Liste des formats √† tester
        export_formats = [
            ("pagecsv", "Export CSV basique des pages"),
            ("fullpagecsv", "Export CSV complet avec contenu readable"),
            ("nodecsv", "Export CSV des domaines avec statistiques"),
            ("mediacsv", "Export CSV des m√©dias"),
            ("pagegexf", "Export GEXF des pages pour visualisation r√©seau"),
            ("nodegexf", "Export GEXF des domaines pour visualisation r√©seau"),
            ("corpus", "Export corpus ZIP avec fichiers texte individuels")
        ]
        
        print(f"\nüìã G√©n√©ration de {len(export_formats)} formats d'export:")
        
        for export_type, description in export_formats:
            try:
                # G√©n√©rer le fichier
                custom_filename = f"tech_news_export_{export_type}_{timestamp}"
                file_path, count = await export_service.export_data(
                    export_type=export_type,
                    land_id=self.test_land.id,
                    minimum_relevance=1,
                    filename=custom_filename
                )
                
                # D√©placer vers le r√©pertoire de sortie
                final_path = os.path.join(output_dir, os.path.basename(file_path))
                if os.path.exists(file_path) and file_path != final_path:
                    os.rename(file_path, final_path)
                    file_path = final_path
                
                self.generated_files.append(file_path)
                
                # V√©rifier le fichier
                assert os.path.exists(file_path)
                file_size = os.path.getsize(file_path)
                
                print(f"  ‚úÖ {export_type.upper()}: {count} records ‚Üí {os.path.basename(file_path)} ({file_size} bytes)")
                print(f"     üìù {description}")
                
                # Validation sp√©cifique par format
                await self._validate_export_file(file_path, export_type, count)
                
            except Exception as e:
                print(f"  ‚ùå {export_type.upper()}: Error - {str(e)}")
                raise e
        
        # Informations finales
        total_size = sum(os.path.getsize(f) for f in self.generated_files if os.path.exists(f))
        print(f"\nüìä R√©sum√© de g√©n√©ration:")
        print(f"  ‚Ä¢ {len(self.generated_files)} fichiers g√©n√©r√©s")
        print(f"  ‚Ä¢ Taille totale: {total_size} bytes ({total_size/1024:.1f} KB)")
        print(f"  ‚Ä¢ R√©pertoire: {output_dir}")
        
        # Cr√©er un fichier README
        readme_path = os.path.join(output_dir, "README.md")
        await self._create_readme(readme_path, timestamp)
        
        print(f"\nüìÅ FICHIERS DISPONIBLES:")
        print(f"üìÇ R√©pertoire principal: {output_dir}")
        for file_path in sorted(self.generated_files):
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                print(f"   üìÑ {os.path.basename(file_path)} ({file_size} bytes)")
        print(f"   üìñ README.md (documentation)")
        
        return output_dir
    
    async def _validate_export_file(self, file_path, export_type, count):
        """Valide le contenu d'un fichier d'export"""
        try:
            if export_type.endswith('csv'):
                # Valider CSV
                import csv
                with open(file_path, 'r', encoding='utf-8') as f:
                    reader = csv.reader(f)
                    rows = list(reader)
                    assert len(rows) >= 1  # Au moins l'en-t√™te
                    if count > 0:
                        assert len(rows) == count + 1  # En-t√™te + donn√©es
            
            elif export_type.endswith('gexf'):
                # Valider GEXF
                tree = etree.parse(file_path)
                root = tree.getroot()
                assert root.tag == 'gexf'
                assert root.get('version') == '1.2'
            
            elif export_type == 'corpus':
                # Valider ZIP
                with ZipFile(file_path, 'r') as archive:
                    files = archive.namelist()
                    assert len(files) == count
                    # V√©rifier qu'au moins un fichier contient du contenu
                    if files:
                        content = archive.read(files[0]).decode('utf-8')
                        assert len(content) > 0
                        assert '---' in content  # M√©tadonn√©es
        
        except Exception as e:
            print(f"    ‚ö†Ô∏è  Validation warning for {export_type}: {str(e)}")
    
    async def _create_readme(self, readme_path, timestamp):
        """Cr√©e un fichier README explicatif"""
        readme_content = f"""# MyWebIntelligence - Fichiers d'Export G√©n√©r√©s

**Date de g√©n√©ration**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**Timestamp**: {timestamp}

## üìä Donn√©es Export√©es

- **Land**: Actualit√©s Tech Export
- **Expressions**: {len(self.test_expressions)} articles de test
- **Domaines**: {len(self.test_domains)} sources (TechCrunch, Le Monde, GitHub)
- **Filtrage**: Relevance minimum = 1

## üìÅ Formats d'Export Disponibles

### CSV Exports
- **tech_news_export_pagecsv_{timestamp}.csv**
  - Export basique des pages avec m√©tadonn√©es
  - Colonnes: id, url, title, description, keywords, relevance, depth, domain info

- **tech_news_export_fullpagecsv_{timestamp}.csv**
  - Export complet incluant le contenu readable des articles
  - Toutes les colonnes de pagecsv + colonne 'readable'

- **tech_news_export_nodecsv_{timestamp}.csv**
  - Export agr√©g√© des domaines avec statistiques
  - Colonnes: id, name, title, description, keywords, expressions count, average relevance

- **tech_news_export_mediacsv_{timestamp}.csv**
  - Export des m√©dias associ√©s aux expressions
  - Colonnes: id, expression_id, url, type

### GEXF Exports (Visualisation R√©seau)
- **tech_news_export_pagegexf_{timestamp}.gexf**
  - R√©seau des pages pour visualisation dans Gephi
  - N≈ìuds = expressions, attributs = m√©tadonn√©es

- **tech_news_export_nodegexf_{timestamp}.gexf**
  - R√©seau des domaines pour visualisation dans Gephi
  - N≈ìuds = domaines, attributs = statistiques

### Corpus Export
- **tech_news_export_corpus_{timestamp}.zip**
  - Archive ZIP contenant un fichier texte par expression
  - Chaque fichier inclut m√©tadonn√©es YAML + contenu readable
  - Format compatible avec outils d'analyse textuelle

## üîß Utilisation

### CSV Files
```bash
# Ouvrir avec Excel, LibreOffice, ou pandas
import pandas as pd
df = pd.read_csv('tech_news_export_pagecsv_{timestamp}.csv')
```

### GEXF Files
```bash
# Ouvrir avec Gephi pour visualisation r√©seau
# File ‚Üí Open ‚Üí S√©lectionner le fichier .gexf
```

### Corpus ZIP
```bash
# Extraire et analyser avec outils de text mining
unzip tech_news_export_corpus_{timestamp}.zip
# Chaque fichier .txt contient m√©tadonn√©es + contenu
```

## üìà Statistiques

- Articles IA/Tech: {sum(1 for expr in self.test_expressions if 'IA' in expr.keywords or 'AI' in expr.keywords)}
- Articles en fran√ßais: {sum(1 for expr in self.test_expressions if 'fran√ßais' in expr.readable or 'France' in expr.keywords)}
- Relevance moyenne: {sum(expr.relevance for expr in self.test_expressions) / len(self.test_expressions):.1f}/10

## üéØ Cas d'Usage

1. **Analyse de Contenu**: Utiliser les CSV pour analyser les tendances
2. **Visualisation R√©seau**: Importer les GEXF dans Gephi
3. **Text Mining**: Extraire le corpus ZIP pour analyse linguistique
4. **Reporting**: Utiliser les CSV pour cr√©er des tableaux de bord

---
G√©n√©r√© par MyWebIntelligence Export System v2.0
"""
        
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        self.generated_files.append(readme_path)


if __name__ == "__main__":
    pytest.main([__file__ + "::TestExportFileGeneration::test_generate_all_export_formats", "-v", "-s"])